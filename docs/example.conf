# MySQL CDC Service - 完整配置示例
# 本文件展示所有可配置项及其说明

cdc {
  # ================================
  # CDC 任务名称
  # ================================
  # 用于区分不同的 CDC 任务
  # 多个任务可以共享同一个元数据库，通过 task-name 区分
  # 建议使用有意义的名称，如：user-sync, order-sync 等
  task-name = "my-cdc-task"

  # ================================
  # 源数据库配置
  # ================================
  source {
    host = "localhost"
    port = 3306
    username = "cdc_user"
    password = "${DB_SOURCE_PASS}"  # 建议使用环境变量
    database = "source_db"
    
    # 连接池配置
    connection-pool {
      max-pool-size = 10          # 最大连接数
      min-idle = 2                # 最小空闲连接数
      connection-timeout = 30s    # 连接超时
    }
  }

  # ================================
  # 目标数据库配置
  # ================================
  target {
    host = "localhost"
    port = 3307
    username = "cdc_user"
    password = "${DB_TARGET_PASS}"  # 建议使用环境变量
    database = "target_db"
    
    # 连接池配置（目标库需要更多连接）
    connection-pool {
      max-pool-size = 20          # 最大连接数
      min-idle = 5                # 最小空闲连接数
      connection-timeout = 30s    # 连接超时
    }
  }

  # ================================
  # 元数据库配置
  # ================================
  # 用于存储 CDC 偏移量等元数据，与业务数据分离
  # 多个 CDC 任务可以共享同一个元数据库
  # 优势：
  # 1. 元数据和业务数据分离，不污染源库
  # 2. 多任务共享，便于统一管理
  # 3. 不会在源库 binlog 中产生 DDL 事件
  metadata {
    host = "localhost"
    port = 3306
    username = "cdc_user"
    password = "${DB_METADATA_PASS}"  # 建议使用环境变量
    database = "xxt_cdc"              # 元数据库名称
    
    # 连接池配置（元数据库连接较少）
    connection-pool {
      max-pool-size = 5           # 最大连接数
      min-idle = 1                # 最小空闲连接数
      connection-timeout = 30s    # 连接超时
    }
  }

  # ================================
  # 表过滤配置
  # ================================
  filter {
    # 包含的数据库（空数组表示所有数据库）
    include-databases = ["source_db", "app_db"]
    
    # 排除的数据库
    exclude-databases = [
      "information_schema",
      "mysql",
      "performance_schema",
      "sys"
    ]
    
    # 包含的表模式（支持正则表达式和通配符）
    include-table-patterns = [
      "users",           # 精确匹配
      "orders.*",        # 通配符：orders 开头的所有表
      "product_.*"       # 通配符：product_ 开头的所有表
    ]
    
    # 排除的表模式
    exclude-table-patterns = [
      "temp_.*",         # 临时表
      ".*_backup",       # 备份表
      ".*_archive",      # 归档表
      "test_.*"          # 测试表
    ]
  }

  # ================================
  # 并行度配置
  # ================================
  parallelism {
    # 路由分区数（影响并行度和内存使用）
    # 建议：16-128，根据表数量和吞吐量调整
    partition-count = 64
    
    # 应用工作线程数（实际并行处理的线程数）
    # 建议：4-32，根据 CPU 核心数调整
    apply-worker-count = 8
    
    # 快照工作线程数（未完成功能，暂时无效）
    snapshot-worker-count = 4
    
    # 批处理大小（每批处理的事件数）
    # 建议：50-1000，根据事件大小和延迟要求调整
    batch-size = 100
    
    # 刷新间隔（强制刷新批次的时间间隔）
    # 建议：500ms-5s，根据延迟要求调整
    flush-interval = 1s
  }

  # ================================
  # 偏移量配置
  # ================================
  offset {
    # 存储类型：mysql 或 file
    # mysql: 存储在目标数据库（推荐生产环境）
    # file: 存储在本地文件（适合开发/测试）
    store-type = "mysql"
    
    # 提交间隔（多久提交一次偏移量）
    # 建议：1s-30s，根据数据一致性要求调整
    # 间隔越短，崩溃恢复时重复处理的数据越少
    commit-interval = 5s
    
    # 启动位置
    # true: 从最新位置开始（跳过历史数据）
    # false: 从头开始（处理所有历史数据）
    start-from-latest = true
    
    # 是否启用快照功能
    # ⚠️ 警告：此功能未完成，生产环境必须设为 false
    enable-snapshot = false
    
    # MySQL 存储配置（当 store-type = "mysql" 时）
    mysql {
      # 偏移量表名
      table-name = "cdc_offsets"
    }
    
    # 文件存储配置（当 store-type = "file" 时）
    file {
      # 偏移量文件路径
      path = "./data/offsets/offset.txt"
    }
  }
}

# ================================
# Pekko 配置
# ================================
pekko {
  # 日志级别：OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "INFO"

  actor {
    provider = "local"
  }

  stream {
    materializer {
      # 流处理缓冲区配置
      max-input-buffer-size = 256
      initial-input-buffer-size = 4
    }
  }
}

# ================================
# 环境变量使用示例
# ================================
# 在启动时设置环境变量：
# export DB_SOURCE_PASS="source_password"
# export DB_TARGET_PASS="target_password"
# export DB_METADATA_PASS="metadata_password"
# java -jar app.jar

# ================================
# 性能调优建议
# ================================
# 1. 高吞吐量场景：
#    - partition-count = 128
#    - apply-worker-count = 16
#    - batch-size = 500
#    - flush-interval = 2s
#
# 2. 低延迟场景：
#    - partition-count = 32
#    - apply-worker-count = 8
#    - batch-size = 50
#    - flush-interval = 500ms
#
# 3. 资源受限场景：
#    - partition-count = 16
#    - apply-worker-count = 4
#    - batch-size = 100
#    - flush-interval = 1s
